{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1PT7qOwuT6T",
        "outputId": "de5ad6f5-e73f-4b12-e28a-ae6d66be91ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKUXg5NRCQSq",
        "outputId": "0b206292-4d4c-4482-e2c5-327a9ddb9b97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install catalyst"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catalyst in /usr/local/lib/python3.6/dist-packages (20.11)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.41.1)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.1)\n",
            "Requirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.22.2.post1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst) (20.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst) (5.5.0)\n",
            "Requirement already satisfied: GitPython>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.1.11)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.1.0)\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.18.5)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.4.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.7.0+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.2.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->catalyst) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->catalyst) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.4.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.35.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.33.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (50.3.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->catalyst) (2.4.7)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (2.6.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=3.1.1->catalyst) (4.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (0.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2020.6.20)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst) (0.2.0)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.1->catalyst) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY8CxiGLvFQn"
      },
      "source": [
        "import os\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from catalyst import dl\n",
        "from catalyst.dl.callbacks import AccuracyCallback, EarlyStoppingCallback"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmYx4H2LVKT5",
        "outputId": "12928a09-19fa-4537-e7f5-cd4a16fe0587",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ROOT_DIR = '/content/drive/My Drive/Colab Notebooks/'\n",
        "TRAIN_SAMPLES_PATH = 'train.csv'\n",
        "VAL_SAMPLES_PATH = 'val.csv'\n",
        "SUBMISSION_FILE = 'submission.csv'\n",
        "MODEL_PATH = 'model.pkt'\n",
        "NUM_CLASSES = 38\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(DEVICE)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiftcXIPUmGC"
      },
      "source": [
        "class MultiClassDataset(Dataset):\n",
        "\n",
        "    def __init__(self , csv_file , img_dir , transform=None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        d = self.df.iloc[idx]\n",
        "        image = Image.open(f'{self.img_dir}/{d.Name}').convert(\"RGB\")\n",
        "        label = torch.tensor(d[1:].tolist() , dtype=torch.float32)\n",
        "    \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkUQ4D7Iy3O7"
      },
      "source": [
        "df = pd.read_csv(ROOT_DIR + 'data/training_labels.csv')\n",
        "df_train, df_val = train_test_split(df, test_size = 0.1)\n",
        "\n",
        "df_train.to_csv(TRAIN_SAMPLES_PATH, index=False)\n",
        "df_val.to_csv(VAL_SAMPLES_PATH, index=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NifklEseVIIx",
        "outputId": "2e2da77b-5c11-4ce9-8087-3014de8271a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.RandomHorizontalFlip()                                 \n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "training_set = MultiClassDataset(TRAIN_SAMPLES_PATH , ROOT_DIR + 'data/training_images' , transform_train)\n",
        "validation_set = MultiClassDataset(VAL_SAMPLES_PATH , ROOT_DIR + 'data/training_images' , transform_val)\n",
        "\n",
        "print(f'Number of samples: Train: {len(training_set)}, Validation: {len(validation_set)}')\n",
        "loaders = {\n",
        "    \"train\":DataLoader(training_set , shuffle=True, batch_size=batch_size),\n",
        "    \"valid\": DataLoader(validation_set , shuffle=False, batch_size=batch_size)\n",
        "    }"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: Train: 3370, Validation: 375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUtOBabIXnza"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def get_classification_network(in_features, num_classes):\n",
        "    return nn.Sequential(\n",
        "         nn.Linear(in_features, in_features // 2),\n",
        "         nn.BatchNorm1d(in_features // 2),\n",
        "         nn.ReLU(),\n",
        "         nn.Dropout(p = 0.5),\n",
        "         nn.Linear(in_features // 2, in_features // 4),\n",
        "         nn.BatchNorm1d(in_features // 4),\n",
        "         nn.ReLU(),\n",
        "         nn.Dropout(p = 0.5),\n",
        "         nn.Linear(in_features // 4, in_features // 8),\n",
        "         nn.BatchNorm1d(in_features // 8),\n",
        "         nn.ReLU(),\n",
        "         nn.Dropout(p = 0.5),\n",
        "         nn.Linear(in_features // 8, num_classes)\n",
        "    )\n",
        "\n",
        "def get_model(num_classes, feature_extract=True):\n",
        "    model = models.resnext101_32x8d(pretrained = True)\n",
        "    set_parameter_requires_grad(model, feature_extract)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = get_classification_network(num_ftrs, num_classes)\n",
        "    return model\n",
        "\n",
        "def skyhacks_f1_score(preds, y):\n",
        "    return f1_score(y, preds, average = 'macro')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWyha4HPeVhF"
      },
      "source": [
        "model = get_model(NUM_CLASSES)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNe_-PHmB_2R"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "callbacks = [\n",
        "    EarlyStoppingCallback(patience=5, metric = 'f1-score', minimize = False)\n",
        "]\n",
        "num_epochs = 100\n",
        "\n",
        "class CustomRunner(dl.Runner):\n",
        "    \n",
        "    def predict_batch(self, batch):\n",
        "        x, y = batch\n",
        "        return self.model(x.to(self.device))\n",
        "    \n",
        "    def _handle_batch(self, batch):\n",
        "        x, y = batch\n",
        "        output = self.model(x)\n",
        "        loss = self.state.criterion(output, y)\n",
        "\n",
        "        preds = torch.sigmoid(output).data > 0.5\n",
        "        preds = preds.to(torch.float32)\n",
        "\n",
        "        f1 = skyhacks_f1_score(preds.cpu().numpy(), y.cpu().numpy())\n",
        "        self.batch_metrics = {\n",
        "            \"loss\": loss,\n",
        "            \"f1-score\": f1\n",
        "        }\n",
        "        \n",
        "        if self.state.is_train_loader:\n",
        "            loss.backward()\n",
        "            self.state.optimizer.step()\n",
        "            self.state.optimizer.zero_grad()           \n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jauRyODeaLan",
        "outputId": "36cb5467-606d-49ac-f584-ff29b28dce9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "runner = CustomRunner()\n",
        "\n",
        "runner.train(\n",
        "    loaders=loaders,\n",
        "    model=model, \n",
        "    criterion=criterion, \n",
        "    optimizer=optimizer,\n",
        "    callbacks=callbacks,\n",
        "    num_epochs=num_epochs, \n",
        "    logdir=\"./logs\", \n",
        "    verbose=True\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/100 * Epoch (train):  17% 9/53 [00:32<02:40,  3.65s/it, f1-score=0.135, loss=0.466]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning:\n",
            "\n",
            "F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/100 * Epoch (train): 100% 53/53 [03:19<00:00,  3.77s/it, f1-score=0.142, loss=0.233]\n",
            "1/100 * Epoch (valid): 100% 6/6 [00:17<00:00,  2.83s/it, f1-score=0.192, loss=0.209]\n",
            "[2020-11-14 18:14:09,994] \n",
            "1/100 * Epoch 1 (train): f1-score=0.1156 | loss=0.3245\n",
            "1/100 * Epoch 1 (valid): f1-score=0.1852 | loss=0.2118\n",
            "2/100 * Epoch (train): 100% 53/53 [03:19<00:00,  3.77s/it, f1-score=0.145, loss=0.190]\n",
            "2/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.79s/it, f1-score=0.268, loss=0.180]\n",
            "[2020-11-14 18:18:11,952] \n",
            "2/100 * Epoch 2 (train): f1-score=0.1708 | loss=0.2069\n",
            "2/100 * Epoch 2 (valid): f1-score=0.2386 | loss=0.1877\n",
            "3/100 * Epoch (train): 100% 53/53 [03:16<00:00,  3.71s/it, f1-score=0.250, loss=0.205]\n",
            "3/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.75s/it, f1-score=0.279, loss=0.172]\n",
            "[2020-11-14 18:22:13,646] \n",
            "3/100 * Epoch 3 (train): f1-score=0.2060 | loss=0.1941\n",
            "3/100 * Epoch 3 (valid): f1-score=0.2633 | loss=0.1790\n",
            "4/100 * Epoch (train): 100% 53/53 [03:17<00:00,  3.72s/it, f1-score=0.235, loss=0.166]\n",
            "4/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.75s/it, f1-score=0.326, loss=0.167]\n",
            "[2020-11-14 18:26:16,037] \n",
            "4/100 * Epoch 4 (train): f1-score=0.2474 | loss=0.1868\n",
            "4/100 * Epoch 4 (valid): f1-score=0.3243 | loss=0.1758\n",
            "5/100 * Epoch (train): 100% 53/53 [03:20<00:00,  3.79s/it, f1-score=0.199, loss=0.171]\n",
            "5/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.74s/it, f1-score=0.304, loss=0.166]\n",
            "[2020-11-14 18:30:17,975] \n",
            "5/100 * Epoch 5 (train): f1-score=0.2777 | loss=0.1814\n",
            "5/100 * Epoch 5 (valid): f1-score=0.3201 | loss=0.1738\n",
            "6/100 * Epoch (train): 100% 53/53 [03:15<00:00,  3.68s/it, f1-score=0.269, loss=0.184]\n",
            "6/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.71s/it, f1-score=0.328, loss=0.164]\n",
            "[2020-11-14 18:34:15,011] \n",
            "6/100 * Epoch 6 (train): f1-score=0.2974 | loss=0.1771\n",
            "6/100 * Epoch 6 (valid): f1-score=0.3370 | loss=0.1737\n",
            "7/100 * Epoch (train): 100% 53/53 [03:18<00:00,  3.75s/it, f1-score=0.284, loss=0.204]\n",
            "7/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.75s/it, f1-score=0.341, loss=0.161]\n",
            "[2020-11-14 18:38:16,449] \n",
            "7/100 * Epoch 7 (train): f1-score=0.3204 | loss=0.1744\n",
            "7/100 * Epoch 7 (valid): f1-score=0.3598 | loss=0.1709\n",
            "8/100 * Epoch (train): 100% 53/53 [03:16<00:00,  3.71s/it, f1-score=0.245, loss=0.184]\n",
            "8/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.72s/it, f1-score=0.356, loss=0.163]\n",
            "[2020-11-14 18:42:17,709] \n",
            "8/100 * Epoch 8 (train): f1-score=0.3332 | loss=0.1724\n",
            "8/100 * Epoch 8 (valid): f1-score=0.3660 | loss=0.1736\n",
            "9/100 * Epoch (train): 100% 53/53 [03:17<00:00,  3.73s/it, f1-score=0.347, loss=0.169]\n",
            "9/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.71s/it, f1-score=0.376, loss=0.159]\n",
            "[2020-11-14 18:45:57,479] \n",
            "9/100 * Epoch 9 (train): f1-score=0.3385 | loss=0.1687\n",
            "9/100 * Epoch 9 (valid): f1-score=0.3624 | loss=0.1716\n",
            "10/100 * Epoch (train): 100% 53/53 [03:15<00:00,  3.69s/it, f1-score=0.278, loss=0.182]\n",
            "10/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.71s/it, f1-score=0.391, loss=0.159]\n",
            "[2020-11-14 18:49:34,796] \n",
            "10/100 * Epoch 10 (train): f1-score=0.3514 | loss=0.1679\n",
            "10/100 * Epoch 10 (valid): f1-score=0.3764 | loss=0.1694\n",
            "11/100 * Epoch (train): 100% 53/53 [03:15<00:00,  3.69s/it, f1-score=0.306, loss=0.163]\n",
            "11/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.72s/it, f1-score=0.391, loss=0.161]\n",
            "[2020-11-14 18:53:33,955] \n",
            "11/100 * Epoch 11 (train): f1-score=0.3616 | loss=0.1649\n",
            "11/100 * Epoch 11 (valid): f1-score=0.3945 | loss=0.1681\n",
            "12/100 * Epoch (train): 100% 53/53 [03:20<00:00,  3.78s/it, f1-score=0.389, loss=0.151]\n",
            "12/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.76s/it, f1-score=0.385, loss=0.157]\n",
            "[2020-11-14 18:57:35,864] \n",
            "12/100 * Epoch 12 (train): f1-score=0.3617 | loss=0.1636\n",
            "12/100 * Epoch 12 (valid): f1-score=0.3991 | loss=0.1698\n",
            "13/100 * Epoch (train): 100% 53/53 [03:17<00:00,  3.73s/it, f1-score=0.350, loss=0.173]\n",
            "13/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.73s/it, f1-score=0.352, loss=0.161]\n",
            "[2020-11-14 19:01:16,512] \n",
            "13/100 * Epoch 13 (train): f1-score=0.3691 | loss=0.1622\n",
            "13/100 * Epoch 13 (valid): f1-score=0.3819 | loss=0.1710\n",
            "14/100 * Epoch (train): 100% 53/53 [03:14<00:00,  3.67s/it, f1-score=0.395, loss=0.167]\n",
            "14/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.73s/it, f1-score=0.389, loss=0.161]\n",
            "[2020-11-14 19:04:53,108] \n",
            "14/100 * Epoch 14 (train): f1-score=0.3841 | loss=0.1619\n",
            "14/100 * Epoch 14 (valid): f1-score=0.3853 | loss=0.1705\n",
            "15/100 * Epoch (train): 100% 53/53 [03:14<00:00,  3.67s/it, f1-score=0.307, loss=0.145]\n",
            "15/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.73s/it, f1-score=0.377, loss=0.163]\n",
            "[2020-11-14 19:08:29,718] \n",
            "15/100 * Epoch 15 (train): f1-score=0.3889 | loss=0.1589\n",
            "15/100 * Epoch 15 (valid): f1-score=0.3936 | loss=0.1701\n",
            "16/100 * Epoch (train): 100% 53/53 [03:14<00:00,  3.66s/it, f1-score=0.436, loss=0.164]\n",
            "16/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.73s/it, f1-score=0.394, loss=0.162]\n",
            "[2020-11-14 19:12:09,016] \n",
            "16/100 * Epoch 16 (train): f1-score=0.3917 | loss=0.1590\n",
            "16/100 * Epoch 16 (valid): f1-score=0.3985 | loss=0.1707\n",
            "17/100 * Epoch (train): 100% 53/53 [03:16<00:00,  3.72s/it, f1-score=0.326, loss=0.138]\n",
            "17/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.72s/it, f1-score=0.391, loss=0.157]\n",
            "[2020-11-14 19:15:48,065] \n",
            "17/100 * Epoch 17 (train): f1-score=0.4006 | loss=0.1557\n",
            "17/100 * Epoch 17 (valid): f1-score=0.4133 | loss=0.1678\n",
            "18/100 * Epoch (train): 100% 53/53 [03:14<00:00,  3.68s/it, f1-score=0.272, loss=0.169]\n",
            "18/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.72s/it, f1-score=0.424, loss=0.160]\n",
            "[2020-11-14 19:19:47,127] \n",
            "18/100 * Epoch 18 (train): f1-score=0.4196 | loss=0.1564\n",
            "18/100 * Epoch 18 (valid): f1-score=0.4133 | loss=0.1707\n",
            "19/100 * Epoch (train): 100% 53/53 [03:13<00:00,  3.65s/it, f1-score=0.458, loss=0.143]\n",
            "19/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.73s/it, f1-score=0.400, loss=0.156]\n",
            "[2020-11-14 19:23:22,904] \n",
            "19/100 * Epoch 19 (train): f1-score=0.4001 | loss=0.1534\n",
            "19/100 * Epoch 19 (valid): f1-score=0.4053 | loss=0.1705\n",
            "20/100 * Epoch (train): 100% 53/53 [03:15<00:00,  3.69s/it, f1-score=0.341, loss=0.155]\n",
            "20/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.73s/it, f1-score=0.378, loss=0.163]\n",
            "[2020-11-14 19:27:00,872] \n",
            "20/100 * Epoch 20 (train): f1-score=0.4127 | loss=0.1522\n",
            "20/100 * Epoch 20 (valid): f1-score=0.4128 | loss=0.1750\n",
            "21/100 * Epoch (train): 100% 53/53 [03:12<00:00,  3.64s/it, f1-score=0.420, loss=0.162]\n",
            "21/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.71s/it, f1-score=0.394, loss=0.163]\n",
            "[2020-11-14 19:30:35,841] \n",
            "21/100 * Epoch 21 (train): f1-score=0.4163 | loss=0.1515\n",
            "21/100 * Epoch 21 (valid): f1-score=0.4275 | loss=0.1725\n",
            "22/100 * Epoch (train): 100% 53/53 [03:12<00:00,  3.64s/it, f1-score=0.389, loss=0.186]\n",
            "22/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.72s/it, f1-score=0.401, loss=0.161]\n",
            "[2020-11-14 19:34:11,184] \n",
            "22/100 * Epoch 22 (train): f1-score=0.4287 | loss=0.1490\n",
            "22/100 * Epoch 22 (valid): f1-score=0.4146 | loss=0.1703\n",
            "23/100 * Epoch (train): 100% 53/53 [03:13<00:00,  3.65s/it, f1-score=0.366, loss=0.154]\n",
            "23/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.72s/it, f1-score=0.416, loss=0.160]\n",
            "[2020-11-14 19:37:48,126] \n",
            "23/100 * Epoch 23 (train): f1-score=0.4431 | loss=0.1478\n",
            "23/100 * Epoch 23 (valid): f1-score=0.4153 | loss=0.1725\n",
            "24/100 * Epoch (train): 100% 53/53 [03:14<00:00,  3.67s/it, f1-score=0.386, loss=0.153]\n",
            "24/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.74s/it, f1-score=0.378, loss=0.159]\n",
            "[2020-11-14 19:41:25,290] \n",
            "24/100 * Epoch 24 (train): f1-score=0.4461 | loss=0.1480\n",
            "24/100 * Epoch 24 (valid): f1-score=0.4091 | loss=0.1709\n",
            "25/100 * Epoch (train): 100% 53/53 [03:16<00:00,  3.71s/it, f1-score=0.410, loss=0.154]\n",
            "25/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.73s/it, f1-score=0.409, loss=0.161]\n",
            "[2020-11-14 19:45:04,303] \n",
            "25/100 * Epoch 25 (train): f1-score=0.4371 | loss=0.1479\n",
            "25/100 * Epoch 25 (valid): f1-score=0.4439 | loss=0.1692\n",
            "26/100 * Epoch (train): 100% 53/53 [03:17<00:00,  3.74s/it, f1-score=0.332, loss=0.148]\n",
            "26/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.82s/it, f1-score=0.447, loss=0.157]\n",
            "[2020-11-14 19:48:44,797] \n",
            "26/100 * Epoch 26 (train): f1-score=0.4498 | loss=0.1462\n",
            "26/100 * Epoch 26 (valid): f1-score=0.4349 | loss=0.1703\n",
            "27/100 * Epoch (train): 100% 53/53 [03:15<00:00,  3.69s/it, f1-score=0.393, loss=0.142]\n",
            "27/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.74s/it, f1-score=0.387, loss=0.167]\n",
            "[2020-11-14 19:52:22,665] \n",
            "27/100 * Epoch 27 (train): f1-score=0.4509 | loss=0.1448\n",
            "27/100 * Epoch 27 (valid): f1-score=0.4138 | loss=0.1748\n",
            "28/100 * Epoch (train): 100% 53/53 [03:14<00:00,  3.66s/it, f1-score=0.418, loss=0.151]\n",
            "28/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.72s/it, f1-score=0.366, loss=0.158]\n",
            "[2020-11-14 19:55:58,776] \n",
            "28/100 * Epoch 28 (train): f1-score=0.4576 | loss=0.1444\n",
            "28/100 * Epoch 28 (valid): f1-score=0.4194 | loss=0.1713\n",
            "29/100 * Epoch (train): 100% 53/53 [03:16<00:00,  3.70s/it, f1-score=0.381, loss=0.146]\n",
            "29/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.78s/it, f1-score=0.397, loss=0.163]\n",
            "[2020-11-14 19:59:37,202] \n",
            "29/100 * Epoch 29 (train): f1-score=0.4646 | loss=0.1417\n",
            "29/100 * Epoch 29 (valid): f1-score=0.4253 | loss=0.1726\n",
            "30/100 * Epoch (train): 100% 53/53 [03:19<00:00,  3.77s/it, f1-score=0.482, loss=0.151]\n",
            "30/100 * Epoch (valid): 100% 6/6 [00:16<00:00,  2.78s/it, f1-score=0.384, loss=0.164]\n",
            "[2020-11-14 20:03:19,182] \n",
            "30/100 * Epoch 30 (train): f1-score=0.4642 | loss=0.1429\n",
            "30/100 * Epoch 30 (valid): f1-score=0.4405 | loss=0.1728\n",
            "Early stop at 30 epoch\n",
            "Top best models:\n",
            "logs/checkpoints/train.17.pth\t0.1678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHqwv_sr1A6_",
        "outputId": "3f6c5297-de30-4456-b365-f0bd21bfc485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "torch.save(runner.model, MODEL_PATH)\n",
        "files.download(MODEL_PATH)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_270239b9-417c-419a-9f7f-1d8e942dceba\", \"model.pkt\", 359119920)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CbuPoJG2T8s"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}